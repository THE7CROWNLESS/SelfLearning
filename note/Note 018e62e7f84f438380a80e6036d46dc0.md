# Note

- **闭包**
    
    闭包是指函数和它所引用的变量（环境）组合而成的一个整体。在 Python 中，闭包可以通过在函数内部定义函数，并返回这个函数来实现。这样，返回的函数可以访问它所在的封闭作用域中的变量，即使这些变量在返回的函数被调用时已经不存在了。这种特性使得**闭包非常适合用来实现一些需要记忆状态或者保存上下文的功能，根据不同输入提供功能。**
    
    以下是一个 Python 中使用闭包的例子：
    
    ```
    def make_counter():
        count = 0
        def counter():
            nonlocal count
            count += 1
            return count
        return counter
    
    c = make_counter()
    print(c())  # 输出 1
    print(c())  # 输出 2
    print(c())  # 输出 3
    
    ```
    
    在这个例子中，`make_counter` 函数返回了一个内部定义的函数 `counter`。每次调用 `c()` 都会返回一个递增的计数器值，而计数器的状态是通过闭包的方式保存在 `counter` 函数内部的 `count` 变量中的。
    
- **hook**
    
    在 PyTorch 中，hook 是一种用于在计算图中注册钩子函数的机制，它可以在张量的梯度计算过程中或者计算结束后执行一些额外的操作，比如打印张量的梯度，对梯度进行修改等等。
    
    PyTorch 中的 hook 机制主要有两种用法：
    
    1. `register_hook` 方法：可以在张量计算的过程中注册一个钩子函数，该函数会在梯度计算完成后被调用。这个钩子函数有一个参数，代表张量的梯度。
    2. `register_backward_hook` 方法：可以在张量计算完成后注册一个钩子函数，该函数会在反向传播计算梯度的过程中被调用。这个钩子函数有三个参数，分别代表张量的梯度、计算图中所有的输入张量以及计算图中所有的输出张量。
    
    hook函数是自定义的，放在register_hook（hook）中，当对module注册时其参数输入是固定的（module、fea_in、fea_out）,本身定义中存在的参数一般可以通过闭包实现（外部函数传参且返回hook，内部函数为hook）
    
    以下是一个使用 hook 的例子：
    
    ```
    import torch
    
    def print_grad(grad):
        print(grad)
    
    x = torch.randn(3, requires_grad=True)
    y = x * 2
    z = y.mean()
    
    hook = y.register_hook(print_grad)
    z.backward()
    
    hook.remove()
    
    ```
    
    ```latex
    # 定义钩子
    # 定义字典存储不同层的输出
    activation={}
    # 定义钩子函数
    def get_activation(name):
        def hook(model,input,output): 
     # 此处的参数input以及output就是调用钩子函数的module的输入和输出。
            activation[name]=output.detach()
        return hook
    
    # 目的：可视化features[4]的特征图，也就是第一个maxpool之后的输出特征
    # 使用钩子抓取：
    vgg16.eval()
    vgg16.features[4].register_forward_hook(get_activation('maxpool1'))  # 注册钩子
    vgg16(input_im)  # 网络计算
    maxpool1=activation['maxpool1']  
    print(maxpool1.shape)
    
    //输出：
    torch.Size([1, 64, 112, 112])
    ```
    
    在这个例子中，我们对张量 `y` 注册了一个 hook，该 hook 函数会在 `y` 的梯度计算完成后被调用，将梯度打印出来。然后我们计算了张量 `z` 的梯度，并将其传递回张量 `y` 中。在这个过程中，hook 函数被调用，将梯度打印出来。最后我们通过 `hook.remove()` 来移除这个 hook。
    
- **VAE**
    
    变分自编码器（Variational Autoencoder，VAE）是一种生成模型，与传统的自编码器（Autoencoder，AE）相比，其可以在潜在空间中实现更灵活的生成和操作，并且具有更好的抽象表达能力。**VAE 的主要思想是将输入数据映射到潜在空间中，并通过对潜在空间中的采样来生成新的数据。通过输出概率，在通过概率去预测中间表示，而非想自编码器一样直接得到中间表示。**
    
    为了实现这一点，VAE 引入了一个概率模型，通过最大化输入数据与生成数据之间的下界来训练模型。这个下界由两部分组成：重构误差和潜在空间的 KL 散度。其中，重构误差表示输入数据与生成数据之间的差异，KL 散度表示生成的潜在空间分布与给定的先验分布之间的差异。通过最大化这个下界，VAE 可以学习到一个潜在空间的表示，并在这个潜在空间中实现生成和操作。
    
    原理图：
    
    以下是一个简单的 VAE 的实现：
    
    ```
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    
    class VAE(nn.Module):
        def __init__(self, input_size, hidden_size, latent_size):
            super(VAE, self).__init__()
            self.input_size = input_size
            self.hidden_size = hidden_size
            self.latent_size = latent_size
    
            self.encoder = nn.Sequential(
                nn.Linear(input_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, latent_size * 2)
            )
    
            self.decoder = nn.Sequential(
                nn.Linear(latent_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, hidden_size),
                nn.ReLU(),
                nn.Linear(hidden_size, input_size)
            )
    
        def encode(self, x):
            h = self.encoder(x)
            mu, logvar = h[:, :self.latent_size], h[:, self.latent_size:]
            return mu, logvar
    
        def decode(self, z):
            return self.decoder(z)
    
        def reparameterize(self, mu, logvar):
            std = torch.exp(0.5 * logvar)
            eps = torch.randn_like(std)
            return mu + eps * std
    
        def forward(self, x):
            mu, logvar = self.encode(x)
            z = self.reparameterize(mu, logvar)
            x_hat = self.decode(z)
            return x_hat, mu, logvar
    
        def loss_function(self, x_hat, x, mu, logvar):
            bce = F.binary_cross_entropy_with_logits(x_hat, x, reduction='sum')
            kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
            return bce + kld
    
    input_size = 784
    hidden_size = 256
    latent_size = 20
    
    model = VAE(input_size, hidden_size, latent_size)
    
    ```
    
    在这个例子中，我们定义了一个 VAE 的模型类，并实现了其中的编码器、解码器、重参数化以及前向传播等方法。其中，编码器和解码器都是简单的全连接神经网络，重参数化方法使用了高斯分布的技巧，前向传播方法则将输入数据映射到潜在空间中，并通过解码器将其转换回原始数据空间中。最后，我们实现了一个损失函数，包括重构误差和 KL 散度。通过最小化这个损失函数，我们可以训练我们的 VAE 模型。
    
- **PBS**
    - **PBS简介**
        
        PBS（Portable Batch System）是一种用于管理集群计算资源和作业调度的软件。PBS 可以将大量的计算资源组织成一个高效的计算集群，为用户提供一个方便的、可靠的计算环境。用户可以使用 PBS 提供的命令和接口来提交作业、查询作业状态、管理作业等。以下是 PBS 的一些基本概念和使用方法：
        
        - **节点（Node）**：计算集群中的一个物理计算节点，包含多个 CPU、内存、磁盘等资源。
        - **队列（Queue）**：计算集群中的一个作业队列，用于管理作业的提交和调度。
        - **作业（Job）**：用户提交到计算集群中的任务，包括作业脚本、输入数据、输出结果等。
        - **作业脚本（Script）**：用于描述作业的执行过程和需要使用的资源等信息的脚本文件，通常使用 Shell 脚本或 Python 脚本编写。
        - **提交作业（qsub）**：使用 qsub 命令来提交作业到计算集群中。
        - **查询作业状态（qstat）**：使用 qstat 命令来查询作业的状态，包括作业 ID、作业状态、作业运行时间、作业资源使用情况等。
        - **取消作业（qdel）**：使用 qdel 命令来取消已经提交的作业。
        
        PBS 还提供了一些高级功能，比如：
        
        - **资源限制（Resource Limit）**：可以通过限制作业的资源使用来控制计算集群的负载和资源分配。
        - **作业优先级（Job Priority）**：可以通过设置作业的优先级来调整作业的调度顺序。
        - **作业依赖（Job Dependency）**：可以通过设置作业依赖关系来控制作业提交的顺序和并发度。
        
        PBS 是一个非常强大的作业管理系统，可以方便地管理大规模的计算集群和作业调度。如果你需要在计算集群中运行大规模的计算任务，那么 PBS 可能是一个不错的选择。
        
    - **PBS脚本写作：三部分（资源声明，环境变量，可执行程序）**
        
        资源声明：即规定所需要的节点数，核数，作业名，所要递交的队列
        
        环境变量：即运行作业时，需要的各个节点的基本属性，比如某些软件的路径等
        
        可执行程序：即需要通过MPI来运行的并行程序
        
        ```latex
        脚本声明部分：
        #PBS -N vasp \\设定应用程序名字
        #PBS -l nodes=2:ppn=12      \\启动2个节点每个节点12个核心
        #PBS -l walltime=999:00:00  \\申请999小时的工作，不满足将无法继续进行计算
        #PBS -q batch                \\指明作业队列
        #PBS -V
        #PBS -S /bin/bash           \\让pbs脚本识别bash命令
        环境变量部分：
        
        ### intel                   \\intel包环境变量生效
        source /opt/intel/composer_xe_2015/bin/compilervars.sh intel64 
        
        source /opt/intel/mkl/bin/intel64/mklvars_intel64.sh 
        
        source /opt/intel/impi/5.0.2.044/bin64/mpivars.sh
        
        可执行程序部分：
        cd $PBS_O_WORKDIR
        nprocs=`wc -l < $PBS_NODEFILE`
        exec=/opt/soft/vasp/vasp
        mpirun -genv I_MPI_DEVICE rdma -machinefile $PBS_NODEFILE -np $nprocs $exec\\执行并行程序
        
        ```
        
    - **流程**
        - 写程序（串行/mpi并行程序）—>编译为可执行文件（可能需要source环境变量、编译器等）—>编写.pbs/.lsf脚本文件或者直接命令行—>查看输出文件/日志等
            
            
    - **MPI运行bugs：**
    [环境变量配置文件为什么要使用source_source 配置文件_weixin_43908020的博客-CSDN博客](https://blog.csdn.net/weixin_43908020/article/details/117905435)
        - **ERROR1：”cannot execute binary file”**
            
            linux系统下遇到cannot execute binary file的问题，一般由以下情况造成：
            
            1. 非root用户或者无执行权限
            2. 编译环境不同（程序由其他操作环境复制过来）
            
            对于第一种情况，采用增加执行权限即可 `chmod +x program`
            
            对于第二种情况，重新编译（将编译中的-c去掉可解决问题）；或者将该程序二进制包拷贝过来，重新编译程序。因为我在实际操作过程中发现我将美国的VPS的整个操作系统环境打包后下载到本地服务器上解压后运行其中的程序会有如题所示问题出现，百思不得其解，系统都为centos5.2，最终发现是两者编译环境不同所致：
            
            - 美国VPS是AMD64位处理器
            - 本地服务器是INTEL32位处理器
            
            这两者的硬件编译环境有所差别，导致了这个问题。当然，下载的某些程序非二进制包，可以直接执行的，但却出现该问题，也是因为内核匹配不了CPU，intel是x86的，amd是amd64或是32位版本，对应清楚下载。希望本文对看到的朋友有所帮助。
            
        - **ERROR2：”execvp error on file ./test.o(Permission denied)”**
            - `chmod` 给文件提权
- **MPI**
    
    MPI（Message Passing Interface）是一种并行编程模型和通信协议，用于在多个进程之间实现消息传递和同步。MPI 的主要思想是将一个大任务划分为多个小任务，并将这些小任务分配给不同的进程来执行。进程之间通过发送和接收消息来协调自己的任务，从而实现协同计算。MPI 可以在多种不同的硬件、系统和编程语言上实现，比如单机、集群、GPU 等。
    
    MPI 的编程模型主要包括以下几个方面：
    
    - 进程的创建和销毁：MPI 应用程序由多个进程组成，每个进程都有自己的地址空间和上下文，可以通过 MPI_Init 和 MPI_Finalize 函数来创建和销毁进程。
    - 进程间通信：MPI 应用程序中的进程可以通过发送和接收消息来进行通信，MPI 提供了多种不同类型的消息传递函数，如点对点通信和群体通信等。
    - 进程同步：MPI 应用程序中的进程可以通过同步操作来协调自己的任务，如 MPI_Barrier 函数可以实现等待所有进程都到达一个同步点再继续执行。
    - 进程拓扑：MPI 应用程序中的进程可以组成不同的拓扑结构，如环形、网格等，MPI 也提供了相应的拓扑操作函数来管理这些结构。
    
    以下是一个简单的 MPI 编程的例子：
    
    ```
    from mpi4py import MPI
    
    comm = MPI.COMM_WORLD   #通信子communicator，MPI.COMM_WORLD是全局的通信子
    rank = comm.Get_rank()  
    size = comm.Get_size()
    
    if rank == 0:
        data = list(range(size))
    else:
        data = None
    
    data = comm.scatter(data, root=0)
    print(f"Process {rank} received data {data}")
    
    data = data ** 2
    result = comm.gather(data, root=0)
    
    if rank == 0:
        print(f"Result: {result}")
    
    ```
    
    在这个例子中，我们使用了 MPI 的点对点通信和群体通信函数来实现进程之间的消息传递和同步。首先，我们使用 MPI.COMM_WORLD 创建了一个 MPI 通信器，然后通过 comm.Get_rank 和 comm.Get_size 函数获取了当前进程的编号和总进程数。在进程 0 中，我们生成了一个包含了 0 到 size-1 的整数列表，然后使用 comm.scatter 函数将这个列表分发给其他进程。每个进程接收到了自己的数据后，将其进行平方运算，并使用 comm.gather 函数将结果发送回进程 0。最后，在进程 0 中，我们收集了所有进程的结果，并将其打印出来。
    
    MPI 是一个非常强大的并行编程模型和通信协议，可以帮助我们实现各种复杂的并行计算任务。如果你需要进行大规模的并行计算，那么 MPI 可能是一个不错的选择。
    
- **零散**
    
    C指针int*是种类型，因此int* p，p是变量名，赋值用p = &a或int* p = &a（不能=a，类型不匹配，赋值给p），函数参数（int * p）调用时传（指针类型p）或（&a）
    
    git关联github使用ssh方式，http报错。
    
- **Makefile**
    
    Makefile 是一个包含编译指令的文件，可以**根据文件之间的依赖关系，自动化地生成目标文件。**Makefile 中包含了多条规则，每条规则描述了一个目标文件的生成方法。
    Makefile 的基本语法如下：
    
    ```
    target: dependencies
        command   //Makefile 中的命令必须以一个 Tab 键开头，否则会出现错误。
    
    ```
    
    其中，target 表示目标文件，dependencies 表示目标文件的依赖文件，command 表示生成目标文件的命令。
    
    Makefile 中的规则可以嵌套，即一个规则的 target 可以是另一个规则的 dependencies。Makefile 中还包含了一些特殊的变量和函数，如 $(CC) 表示编译器的名称，$(CFLAGS) 表示编译器的选项等。
    
    Makefile 的使用方法如下：
    
    - 编写 Makefile 文件，描述目标文件之间的依赖关系和生成方法；
    - 在 Makefile 所在的目录中，使用 make 命令编译程序；
    - make 命令会根据 Makefile 中的规则，自动编译生成目标文件。
    
    优点：是可以自动化地生成目标文件，减少了手动编译的工作量。同时，Makefile 中的规则可以描述文件之间的依赖关系，当一个文件发生改变时，只需要重新编译与之相关的文件，提高了编译的效率。
    
    缺点：是需要手动编写文件，对于复杂的程序，需要编写大量的规则，增加了编写的难度。同时，Makefile 中的语法比较繁琐，容易出错。
    
    补充具体示例
    
- **linux**
    
    1、